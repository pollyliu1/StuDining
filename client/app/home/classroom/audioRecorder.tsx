"use client";
import { useState, useRef } from "react";
import Axios from "axios";

export default function AudioRecorder() {
  const [permission, setPermission] = useState(false);
  const mediaRecorder = useRef<MediaRecorder | null>(null);
  const [recordingStatus, setRecordingStatus] = useState("inactive");
  const [stream, setStream] = useState<MediaStream | null>(null);
  const [audioChunks, setAudioChunks] = useState<Blob[]>([]);
  const [audio, setAudio] = useState<string | null>(null);
  const [audioBlob, setAudioBlob] = useState<Blob | null>(null);

  const getMicrophonePermission = async () => {
    if ("MediaRecorder" in window) {
      try {
        const streamData = await navigator.mediaDevices.getUserMedia({
          audio: true,
          video: false,
        });
        setPermission(true);
        setStream(streamData);
        console.log("permission granted");
      } catch (err: string | any) {
        alert(err.message);
      }
    } else {
      console.log("MediaRecorder not supported in your browser");
      alert("The MediaRecorder API is not supported in your browser.");
    }
  };

  const startRecording = async () => {
    getMicrophonePermission();
    if(!permission) return;
    setRecordingStatus("recording");
    //create new Media recorder instance using the stream
    if (stream) {
      const media = new MediaRecorder(stream, { mimeType: "audio/webm" });
      //set the MediaRecorder instance to the mediaRecorder ref
      mediaRecorder.current = media;
      //invokes the start method to start the recording process
      mediaRecorder.current.start(0);
      let localAudioChunks: Blob[] = [];
      mediaRecorder.current.ondataavailable = (event) => {
        if (typeof event.data === "undefined") return;
        if (event.data.size === 0) return;
        localAudioChunks.push(event.data);
      };
      setAudioChunks(localAudioChunks);
    }
  };
  const stopRecording = async () => {
    setRecordingStatus("inactive");
    //stops the recording instance
    if (mediaRecorder.current) {
      mediaRecorder.current.stop();
      mediaRecorder.current.onstop = () => {
        //creates a blob file from the audiochunks data
        const audioBlob = new Blob(audioChunks, { type: "audio/webm" });
        setAudioBlob(audioBlob);
        //creates a playable URL from the blob file.
        const audioUrl = URL.createObjectURL(audioBlob);
        setAudio(audioUrl);
        setTimeout(() => {
          alert("recording stopped");
 
          let formData = new FormData();
          formData.append('audio', audioBlob);

          fetch('http://127.0.0.1:8000/google/', {
            method: 'POST',
            body: formData
          })
          .then(response => response.json())
          .then(data => console.log(data))
          .catch(error => console.error(error));
        }, 200);
       
      };
      
    }
  };
  return (
    <div>
      <main>
        <div className="audio-controls">
          {!permission ? (
            <button className="audio-button" onClick={getMicrophonePermission} type="button">
              Mic
            </button>
          ) : null}
          {permission && recordingStatus === "inactive" ? (
            <button className="audio-button" onClick={() => startRecording()} type="button">
              Start
            </button>
          ) : null}
          {recordingStatus === "recording" ? (
            <button className="audio-button2" onClick={stopRecording} type="button">
              Stop
            </button>
          ) : null}
        </div>
      </main>
    </div>
  );
}
